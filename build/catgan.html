<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<link rel="stylesheet" href="assets/styles.css">
		<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
		<title>AI demos - <%= htmlWebpackPlugin.options.page.name %></title>
	</head>

	<body>
		<div class="content">
			<h3>First something to play with...</h3>
			<div class="fr cat-canvases fac">
				<canvas width="192" height="192" style="width:192px;height:192px;"></canvas>
				<canvas width="192" height="192" style="width:192px;height:192px;"></canvas>
				<canvas width="192" height="192" style="width:192px;height:192px;"></canvas>
				<div class="fc" style="width:150px;">
					<p style="flex: 1;width:100%;;min-width:0px;">
						The images are scaled up 3 times, the original model was trained on 64x64 images.
					</p>
					<div class="btn" id="catgan-btn">Generate</div>
				</div>
			</div>
			<h3>... then some explanations</h3>
			<h4>How does it work?</h4>
			<p>
				I used an image generation technique called <strong>Generative Adversarial Networks (GANs)</strong>.
				It's a fascinating idea; you are actually training two networks; a <strong>generator</strong> and a <strong>discriminator</strong>.
				The generator is given completely random noise as input, and its output is a an image (array of pixels).
				The discriminator is given an image as input, and its output is a single number, which says whether the input is real or not.
				<br><br>
				The key part is in how the two models are evaluated. The discriminator is always given two images; one from the real dataset, one generated by the generator.
				It is evaluated on how well it can tell what is real and what is fake. Conversely, the generator is trying to fool the discriminator.
				It is trying to generate images that will make the generator say "this is real". During this arms race, both models are getting better,
				and eventually the generator's outputs are good enough that we can use them.
			</p>
			<h4>The training process</h4>
			<div class="fr fjc">
				<img src="assets/images/catgan-training.gif" width="250"/>
				<p>
					On the left you can see how the generator does progressively better as it trains more.
					I was able to do this by following Tensorflow's wonderful <a href="https://www.tensorflow.org/tutorials/generative/dcgan" target="_blank">tutorial on GANs</a>,
					and adapting it to my use case.
					<br><br>
					In total, the training took around 600 epochs, or around 100 minutes.
					<br><br>
					You can observe how the various necessary aspects evolved; the rough shape of the cat face emerged quickly, followed by more micro features, followed by color accurracy.
				</p>
			</div>
		</div>
	</body>
</html>